[ Wed Nov  2 18:28:13 2022 ] using warm up, epoch: 5
[ Wed Nov  2 18:28:21 2022 ] Parameters:
{'work_dir': './work_dir/sigmoidplus', 'model_saved_name': './work_dir/sigmoidplus/runs', 'config': './config/nturgbd-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': '../../data/ntu/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': '../../data/ntu/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Nov  2 18:28:21 2022 ] # Parameters: 1446672
[ Wed Nov  2 18:28:21 2022 ] Training epoch: 1
[ Wed Nov  2 18:34:33 2022 ] 	Mean training loss: 2.4603.  Mean training acc: 32.35%.
[ Wed Nov  2 18:34:33 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 18:34:33 2022 ] Eval epoch: 1
[ Wed Nov  2 18:35:08 2022 ] 	Mean test loss of 258 batches: 1.6368117011332697.
[ Wed Nov  2 18:35:08 2022 ] 	Top1: 52.56%
[ Wed Nov  2 18:35:09 2022 ] 	Top5: 85.71%
[ Wed Nov  2 18:35:09 2022 ] Training epoch: 2
[ Wed Nov  2 18:41:21 2022 ] 	Mean training loss: 1.5732.  Mean training acc: 52.53%.
[ Wed Nov  2 18:41:21 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 18:41:21 2022 ] Eval epoch: 2
[ Wed Nov  2 18:41:57 2022 ] 	Mean test loss of 258 batches: 1.2726833094922148.
[ Wed Nov  2 18:41:57 2022 ] 	Top1: 61.47%
[ Wed Nov  2 18:41:57 2022 ] 	Top5: 91.19%
[ Wed Nov  2 18:41:57 2022 ] Training epoch: 3
[ Wed Nov  2 18:48:09 2022 ] 	Mean training loss: 1.2308.  Mean training acc: 62.36%.
[ Wed Nov  2 18:48:09 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 18:48:09 2022 ] Eval epoch: 3
[ Wed Nov  2 18:48:45 2022 ] 	Mean test loss of 258 batches: 1.3329693444015445.
[ Wed Nov  2 18:48:45 2022 ] 	Top1: 60.25%
[ Wed Nov  2 18:48:45 2022 ] 	Top5: 90.04%
[ Wed Nov  2 18:48:45 2022 ] Training epoch: 4
[ Wed Nov  2 18:54:58 2022 ] 	Mean training loss: 1.0400.  Mean training acc: 67.76%.
[ Wed Nov  2 18:54:58 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 18:54:58 2022 ] Eval epoch: 4
[ Wed Nov  2 18:55:33 2022 ] 	Mean test loss of 258 batches: 1.0659233798352323.
[ Wed Nov  2 18:55:33 2022 ] 	Top1: 68.19%
[ Wed Nov  2 18:55:33 2022 ] 	Top5: 92.56%
[ Wed Nov  2 18:55:34 2022 ] Training epoch: 5
[ Wed Nov  2 19:01:46 2022 ] 	Mean training loss: 0.9455.  Mean training acc: 70.91%.
[ Wed Nov  2 19:01:46 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:01:46 2022 ] Eval epoch: 5
[ Wed Nov  2 19:02:22 2022 ] 	Mean test loss of 258 batches: 1.1404529139977093.
[ Wed Nov  2 19:02:22 2022 ] 	Top1: 67.25%
[ Wed Nov  2 19:02:22 2022 ] 	Top5: 92.50%
[ Wed Nov  2 19:02:22 2022 ] Training epoch: 6
[ Wed Nov  2 19:08:34 2022 ] 	Mean training loss: 0.8377.  Mean training acc: 73.89%.
[ Wed Nov  2 19:08:34 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:08:34 2022 ] Eval epoch: 6
[ Wed Nov  2 19:09:10 2022 ] 	Mean test loss of 258 batches: 0.9929425738347594.
[ Wed Nov  2 19:09:10 2022 ] 	Top1: 70.89%
[ Wed Nov  2 19:09:10 2022 ] 	Top5: 92.44%
[ Wed Nov  2 19:09:10 2022 ] Training epoch: 7
[ Wed Nov  2 19:15:23 2022 ] 	Mean training loss: 0.7792.  Mean training acc: 75.61%.
[ Wed Nov  2 19:15:23 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:15:23 2022 ] Eval epoch: 7
[ Wed Nov  2 19:15:59 2022 ] 	Mean test loss of 258 batches: 0.870122623304988.
[ Wed Nov  2 19:15:59 2022 ] 	Top1: 74.09%
[ Wed Nov  2 19:15:59 2022 ] 	Top5: 94.58%
[ Wed Nov  2 19:15:59 2022 ] Training epoch: 8
[ Wed Nov  2 19:22:11 2022 ] 	Mean training loss: 0.7405.  Mean training acc: 76.95%.
[ Wed Nov  2 19:22:11 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:22:11 2022 ] Eval epoch: 8
[ Wed Nov  2 19:22:47 2022 ] 	Mean test loss of 258 batches: 0.8895275172337082.
[ Wed Nov  2 19:22:47 2022 ] 	Top1: 73.43%
[ Wed Nov  2 19:22:47 2022 ] 	Top5: 94.63%
[ Wed Nov  2 19:22:47 2022 ] Training epoch: 9
[ Wed Nov  2 19:28:59 2022 ] 	Mean training loss: 0.7170.  Mean training acc: 77.59%.
[ Wed Nov  2 19:28:59 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:28:59 2022 ] Eval epoch: 9
[ Wed Nov  2 19:29:35 2022 ] 	Mean test loss of 258 batches: 0.938300335245539.
[ Wed Nov  2 19:29:35 2022 ] 	Top1: 72.52%
[ Wed Nov  2 19:29:35 2022 ] 	Top5: 94.26%
[ Wed Nov  2 19:29:35 2022 ] Training epoch: 10
[ Wed Nov  2 19:35:47 2022 ] 	Mean training loss: 0.6842.  Mean training acc: 78.62%.
[ Wed Nov  2 19:35:47 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:35:47 2022 ] Eval epoch: 10
[ Wed Nov  2 19:36:23 2022 ] 	Mean test loss of 258 batches: 0.9297103486781897.
[ Wed Nov  2 19:36:23 2022 ] 	Top1: 73.42%
[ Wed Nov  2 19:36:24 2022 ] 	Top5: 94.43%
[ Wed Nov  2 19:36:24 2022 ] Training epoch: 11
[ Wed Nov  2 19:42:36 2022 ] 	Mean training loss: 0.6771.  Mean training acc: 78.81%.
[ Wed Nov  2 19:42:36 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:42:36 2022 ] Eval epoch: 11
[ Wed Nov  2 19:43:12 2022 ] 	Mean test loss of 258 batches: 0.9426253733708877.
[ Wed Nov  2 19:43:12 2022 ] 	Top1: 72.01%
[ Wed Nov  2 19:43:12 2022 ] 	Top5: 94.08%
[ Wed Nov  2 19:43:12 2022 ] Training epoch: 12
[ Wed Nov  2 19:49:24 2022 ] 	Mean training loss: 0.6504.  Mean training acc: 79.63%.
[ Wed Nov  2 19:49:24 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:49:24 2022 ] Eval epoch: 12
[ Wed Nov  2 19:50:00 2022 ] 	Mean test loss of 258 batches: 0.8372639482335527.
[ Wed Nov  2 19:50:00 2022 ] 	Top1: 74.86%
[ Wed Nov  2 19:50:00 2022 ] 	Top5: 94.38%
[ Wed Nov  2 19:50:00 2022 ] Training epoch: 13
[ Wed Nov  2 19:56:13 2022 ] 	Mean training loss: 0.6301.  Mean training acc: 80.35%.
[ Wed Nov  2 19:56:13 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 19:56:13 2022 ] Eval epoch: 13
[ Wed Nov  2 19:56:49 2022 ] 	Mean test loss of 258 batches: 0.7529147653154624.
[ Wed Nov  2 19:56:49 2022 ] 	Top1: 76.95%
[ Wed Nov  2 19:56:49 2022 ] 	Top5: 95.63%
[ Wed Nov  2 19:56:49 2022 ] Training epoch: 14
[ Wed Nov  2 20:03:01 2022 ] 	Mean training loss: 0.6197.  Mean training acc: 80.36%.
[ Wed Nov  2 20:03:01 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:03:01 2022 ] Eval epoch: 14
[ Wed Nov  2 20:03:37 2022 ] 	Mean test loss of 258 batches: 0.8427415716555692.
[ Wed Nov  2 20:03:37 2022 ] 	Top1: 75.27%
[ Wed Nov  2 20:03:37 2022 ] 	Top5: 94.98%
[ Wed Nov  2 20:03:37 2022 ] Training epoch: 15
[ Wed Nov  2 20:09:49 2022 ] 	Mean training loss: 0.6065.  Mean training acc: 80.74%.
[ Wed Nov  2 20:09:49 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:09:49 2022 ] Eval epoch: 15
[ Wed Nov  2 20:10:25 2022 ] 	Mean test loss of 258 batches: 0.8709703433190206.
[ Wed Nov  2 20:10:25 2022 ] 	Top1: 73.32%
[ Wed Nov  2 20:10:25 2022 ] 	Top5: 95.79%
[ Wed Nov  2 20:10:25 2022 ] Training epoch: 16
[ Wed Nov  2 20:16:38 2022 ] 	Mean training loss: 0.5939.  Mean training acc: 81.24%.
[ Wed Nov  2 20:16:38 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:16:38 2022 ] Eval epoch: 16
[ Wed Nov  2 20:17:14 2022 ] 	Mean test loss of 258 batches: 0.7251144421770591.
[ Wed Nov  2 20:17:14 2022 ] 	Top1: 78.02%
[ Wed Nov  2 20:17:14 2022 ] 	Top5: 95.89%
[ Wed Nov  2 20:17:14 2022 ] Training epoch: 17
[ Wed Nov  2 20:23:26 2022 ] 	Mean training loss: 0.5806.  Mean training acc: 81.33%.
[ Wed Nov  2 20:23:26 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:23:26 2022 ] Eval epoch: 17
[ Wed Nov  2 20:24:02 2022 ] 	Mean test loss of 258 batches: 1.6604706887588945.
[ Wed Nov  2 20:24:02 2022 ] 	Top1: 58.75%
[ Wed Nov  2 20:24:02 2022 ] 	Top5: 90.44%
[ Wed Nov  2 20:24:02 2022 ] Training epoch: 18
[ Wed Nov  2 20:30:14 2022 ] 	Mean training loss: 0.5749.  Mean training acc: 81.87%.
[ Wed Nov  2 20:30:14 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:30:14 2022 ] Eval epoch: 18
[ Wed Nov  2 20:30:50 2022 ] 	Mean test loss of 258 batches: 0.779066287269888.
[ Wed Nov  2 20:30:50 2022 ] 	Top1: 77.22%
[ Wed Nov  2 20:30:50 2022 ] 	Top5: 95.74%
[ Wed Nov  2 20:30:50 2022 ] Training epoch: 19
[ Wed Nov  2 20:37:03 2022 ] 	Mean training loss: 0.5720.  Mean training acc: 81.95%.
[ Wed Nov  2 20:37:03 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:37:03 2022 ] Eval epoch: 19
[ Wed Nov  2 20:38:17 2022 ] 	Mean test loss of 258 batches: 0.7141531872194867.
[ Wed Nov  2 20:38:17 2022 ] 	Top1: 78.43%
[ Wed Nov  2 20:38:17 2022 ] 	Top5: 96.15%
[ Wed Nov  2 20:38:17 2022 ] Training epoch: 20
[ Wed Nov  2 20:44:30 2022 ] 	Mean training loss: 0.5629.  Mean training acc: 82.33%.
[ Wed Nov  2 20:44:30 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:44:30 2022 ] Eval epoch: 20
[ Wed Nov  2 20:45:06 2022 ] 	Mean test loss of 258 batches: 0.8136718592555948.
[ Wed Nov  2 20:45:06 2022 ] 	Top1: 75.86%
[ Wed Nov  2 20:45:06 2022 ] 	Top5: 95.00%
[ Wed Nov  2 20:45:06 2022 ] Training epoch: 21
[ Wed Nov  2 20:51:18 2022 ] 	Mean training loss: 0.5560.  Mean training acc: 82.40%.
[ Wed Nov  2 20:51:18 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:51:18 2022 ] Eval epoch: 21
[ Wed Nov  2 20:51:54 2022 ] 	Mean test loss of 258 batches: 0.7351255875456241.
[ Wed Nov  2 20:51:54 2022 ] 	Top1: 77.58%
[ Wed Nov  2 20:51:54 2022 ] 	Top5: 96.04%
[ Wed Nov  2 20:51:54 2022 ] Training epoch: 22
[ Wed Nov  2 20:58:07 2022 ] 	Mean training loss: 0.5533.  Mean training acc: 82.46%.
[ Wed Nov  2 20:58:07 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 20:58:07 2022 ] Eval epoch: 22
[ Wed Nov  2 20:58:43 2022 ] 	Mean test loss of 258 batches: 0.7168580723940864.
[ Wed Nov  2 20:58:43 2022 ] 	Top1: 77.93%
[ Wed Nov  2 20:58:43 2022 ] 	Top5: 96.59%
[ Wed Nov  2 20:58:43 2022 ] Training epoch: 23
[ Wed Nov  2 21:04:55 2022 ] 	Mean training loss: 0.5402.  Mean training acc: 83.06%.
[ Wed Nov  2 21:04:55 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:04:55 2022 ] Eval epoch: 23
[ Wed Nov  2 21:05:31 2022 ] 	Mean test loss of 258 batches: 0.6301171699351118.
[ Wed Nov  2 21:05:31 2022 ] 	Top1: 80.76%
[ Wed Nov  2 21:05:31 2022 ] 	Top5: 96.68%
[ Wed Nov  2 21:05:31 2022 ] Training epoch: 24
[ Wed Nov  2 21:11:43 2022 ] 	Mean training loss: 0.5421.  Mean training acc: 82.75%.
[ Wed Nov  2 21:11:43 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:11:43 2022 ] Eval epoch: 24
[ Wed Nov  2 21:12:19 2022 ] 	Mean test loss of 258 batches: 0.8770495692426844.
[ Wed Nov  2 21:12:19 2022 ] 	Top1: 75.27%
[ Wed Nov  2 21:12:19 2022 ] 	Top5: 94.69%
[ Wed Nov  2 21:12:19 2022 ] Training epoch: 25
[ Wed Nov  2 21:18:32 2022 ] 	Mean training loss: 0.5442.  Mean training acc: 82.76%.
[ Wed Nov  2 21:18:32 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:18:32 2022 ] Eval epoch: 25
[ Wed Nov  2 21:19:08 2022 ] 	Mean test loss of 258 batches: 0.7978413740331812.
[ Wed Nov  2 21:19:08 2022 ] 	Top1: 75.68%
[ Wed Nov  2 21:19:08 2022 ] 	Top5: 95.53%
[ Wed Nov  2 21:19:08 2022 ] Training epoch: 26
[ Wed Nov  2 21:25:20 2022 ] 	Mean training loss: 0.5323.  Mean training acc: 83.19%.
[ Wed Nov  2 21:25:20 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:25:20 2022 ] Eval epoch: 26
[ Wed Nov  2 21:25:56 2022 ] 	Mean test loss of 258 batches: 0.6082726020452588.
[ Wed Nov  2 21:25:56 2022 ] 	Top1: 80.56%
[ Wed Nov  2 21:25:56 2022 ] 	Top5: 97.05%
[ Wed Nov  2 21:25:56 2022 ] Training epoch: 27
[ Wed Nov  2 21:32:08 2022 ] 	Mean training loss: 0.5296.  Mean training acc: 83.03%.
[ Wed Nov  2 21:32:08 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:32:08 2022 ] Eval epoch: 27
[ Wed Nov  2 21:32:44 2022 ] 	Mean test loss of 258 batches: 0.6950523471531942.
[ Wed Nov  2 21:32:44 2022 ] 	Top1: 78.43%
[ Wed Nov  2 21:32:44 2022 ] 	Top5: 96.04%
[ Wed Nov  2 21:32:44 2022 ] Training epoch: 28
[ Wed Nov  2 21:38:56 2022 ] 	Mean training loss: 0.5215.  Mean training acc: 83.55%.
[ Wed Nov  2 21:38:56 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:38:56 2022 ] Eval epoch: 28
[ Wed Nov  2 21:39:32 2022 ] 	Mean test loss of 258 batches: 0.7618782147187595.
[ Wed Nov  2 21:39:32 2022 ] 	Top1: 77.98%
[ Wed Nov  2 21:39:32 2022 ] 	Top5: 95.43%
[ Wed Nov  2 21:39:32 2022 ] Training epoch: 29
[ Wed Nov  2 21:45:45 2022 ] 	Mean training loss: 0.5230.  Mean training acc: 83.39%.
[ Wed Nov  2 21:45:45 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:45:45 2022 ] Eval epoch: 29
[ Wed Nov  2 21:46:20 2022 ] 	Mean test loss of 258 batches: 0.7968568956667139.
[ Wed Nov  2 21:46:20 2022 ] 	Top1: 77.45%
[ Wed Nov  2 21:46:21 2022 ] 	Top5: 94.89%
[ Wed Nov  2 21:46:21 2022 ] Training epoch: 30
[ Wed Nov  2 21:52:33 2022 ] 	Mean training loss: 0.5251.  Mean training acc: 83.24%.
[ Wed Nov  2 21:52:33 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:52:33 2022 ] Eval epoch: 30
[ Wed Nov  2 21:53:09 2022 ] 	Mean test loss of 258 batches: 0.7792388956214107.
[ Wed Nov  2 21:53:09 2022 ] 	Top1: 77.01%
[ Wed Nov  2 21:53:09 2022 ] 	Top5: 95.09%
[ Wed Nov  2 21:53:09 2022 ] Training epoch: 31
[ Wed Nov  2 21:59:21 2022 ] 	Mean training loss: 0.5143.  Mean training acc: 83.77%.
[ Wed Nov  2 21:59:21 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 21:59:21 2022 ] Eval epoch: 31
[ Wed Nov  2 21:59:57 2022 ] 	Mean test loss of 258 batches: 0.6439980354535487.
[ Wed Nov  2 21:59:57 2022 ] 	Top1: 80.71%
[ Wed Nov  2 21:59:57 2022 ] 	Top5: 96.52%
[ Wed Nov  2 21:59:57 2022 ] Training epoch: 32
[ Wed Nov  2 22:06:09 2022 ] 	Mean training loss: 0.5107.  Mean training acc: 83.82%.
[ Wed Nov  2 22:06:09 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:06:09 2022 ] Eval epoch: 32
[ Wed Nov  2 22:06:45 2022 ] 	Mean test loss of 258 batches: 0.6967763590027195.
[ Wed Nov  2 22:06:45 2022 ] 	Top1: 79.12%
[ Wed Nov  2 22:06:45 2022 ] 	Top5: 96.24%
[ Wed Nov  2 22:06:45 2022 ] Training epoch: 33
[ Wed Nov  2 22:12:58 2022 ] 	Mean training loss: 0.5078.  Mean training acc: 83.98%.
[ Wed Nov  2 22:12:58 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:12:58 2022 ] Eval epoch: 33
[ Wed Nov  2 22:13:33 2022 ] 	Mean test loss of 258 batches: 0.6507354349244473.
[ Wed Nov  2 22:13:33 2022 ] 	Top1: 79.86%
[ Wed Nov  2 22:13:34 2022 ] 	Top5: 96.90%
[ Wed Nov  2 22:13:34 2022 ] Training epoch: 34
[ Wed Nov  2 22:19:46 2022 ] 	Mean training loss: 0.5083.  Mean training acc: 83.87%.
[ Wed Nov  2 22:19:46 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:19:46 2022 ] Eval epoch: 34
[ Wed Nov  2 22:20:22 2022 ] 	Mean test loss of 258 batches: 0.6257752463683601.
[ Wed Nov  2 22:20:22 2022 ] 	Top1: 80.28%
[ Wed Nov  2 22:20:22 2022 ] 	Top5: 96.62%
[ Wed Nov  2 22:20:22 2022 ] Training epoch: 35
[ Wed Nov  2 22:26:34 2022 ] 	Mean training loss: 0.5077.  Mean training acc: 83.98%.
[ Wed Nov  2 22:26:34 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:26:34 2022 ] Eval epoch: 35
[ Wed Nov  2 22:27:10 2022 ] 	Mean test loss of 258 batches: 0.7366056271301683.
[ Wed Nov  2 22:27:10 2022 ] 	Top1: 78.82%
[ Wed Nov  2 22:27:10 2022 ] 	Top5: 96.25%
[ Wed Nov  2 22:27:10 2022 ] Training epoch: 36
[ Wed Nov  2 22:33:22 2022 ] 	Mean training loss: 0.3007.  Mean training acc: 90.67%.
[ Wed Nov  2 22:33:22 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:33:22 2022 ] Eval epoch: 36
[ Wed Nov  2 22:33:58 2022 ] 	Mean test loss of 258 batches: 0.39275998463348827.
[ Wed Nov  2 22:33:58 2022 ] 	Top1: 87.94%
[ Wed Nov  2 22:33:58 2022 ] 	Top5: 98.04%
[ Wed Nov  2 22:33:58 2022 ] Training epoch: 37
[ Wed Nov  2 22:40:11 2022 ] 	Mean training loss: 0.2490.  Mean training acc: 92.26%.
[ Wed Nov  2 22:40:11 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:40:11 2022 ] Eval epoch: 37
[ Wed Nov  2 22:40:47 2022 ] 	Mean test loss of 258 batches: 0.3589919607133366.
[ Wed Nov  2 22:40:47 2022 ] 	Top1: 88.88%
[ Wed Nov  2 22:40:47 2022 ] 	Top5: 98.27%
[ Wed Nov  2 22:40:47 2022 ] Training epoch: 38
[ Wed Nov  2 22:46:59 2022 ] 	Mean training loss: 0.2266.  Mean training acc: 92.91%.
[ Wed Nov  2 22:46:59 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:46:59 2022 ] Eval epoch: 38
[ Wed Nov  2 22:47:35 2022 ] 	Mean test loss of 258 batches: 0.3615069730683815.
[ Wed Nov  2 22:47:35 2022 ] 	Top1: 88.94%
[ Wed Nov  2 22:47:35 2022 ] 	Top5: 98.21%
[ Wed Nov  2 22:47:35 2022 ] Training epoch: 39
[ Wed Nov  2 22:53:48 2022 ] 	Mean training loss: 0.2071.  Mean training acc: 93.65%.
[ Wed Nov  2 22:53:48 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 22:53:48 2022 ] Eval epoch: 39
[ Wed Nov  2 22:54:24 2022 ] 	Mean test loss of 258 batches: 0.3549663555021434.
[ Wed Nov  2 22:54:24 2022 ] 	Top1: 89.31%
[ Wed Nov  2 22:54:24 2022 ] 	Top5: 98.31%
[ Wed Nov  2 22:54:24 2022 ] Training epoch: 40
[ Wed Nov  2 23:00:36 2022 ] 	Mean training loss: 0.1977.  Mean training acc: 93.84%.
[ Wed Nov  2 23:00:36 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:00:36 2022 ] Eval epoch: 40
[ Wed Nov  2 23:01:12 2022 ] 	Mean test loss of 258 batches: 0.3571162095163451.
[ Wed Nov  2 23:01:12 2022 ] 	Top1: 89.11%
[ Wed Nov  2 23:01:12 2022 ] 	Top5: 98.29%
[ Wed Nov  2 23:01:12 2022 ] Training epoch: 41
[ Wed Nov  2 23:07:25 2022 ] 	Mean training loss: 0.1865.  Mean training acc: 94.30%.
[ Wed Nov  2 23:07:25 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:07:25 2022 ] Eval epoch: 41
[ Wed Nov  2 23:08:00 2022 ] 	Mean test loss of 258 batches: 0.3624094617083784.
[ Wed Nov  2 23:08:00 2022 ] 	Top1: 89.11%
[ Wed Nov  2 23:08:01 2022 ] 	Top5: 98.25%
[ Wed Nov  2 23:08:01 2022 ] Training epoch: 42
[ Wed Nov  2 23:14:13 2022 ] 	Mean training loss: 0.1764.  Mean training acc: 94.71%.
[ Wed Nov  2 23:14:13 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:14:13 2022 ] Eval epoch: 42
[ Wed Nov  2 23:14:49 2022 ] 	Mean test loss of 258 batches: 0.36494641151827895.
[ Wed Nov  2 23:14:49 2022 ] 	Top1: 89.22%
[ Wed Nov  2 23:14:49 2022 ] 	Top5: 98.20%
[ Wed Nov  2 23:14:49 2022 ] Training epoch: 43
[ Wed Nov  2 23:21:01 2022 ] 	Mean training loss: 0.1659.  Mean training acc: 95.03%.
[ Wed Nov  2 23:21:01 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:21:01 2022 ] Eval epoch: 43
[ Wed Nov  2 23:21:37 2022 ] 	Mean test loss of 258 batches: 0.37232767894517543.
[ Wed Nov  2 23:21:37 2022 ] 	Top1: 88.64%
[ Wed Nov  2 23:21:37 2022 ] 	Top5: 98.28%
[ Wed Nov  2 23:21:37 2022 ] Training epoch: 44
[ Wed Nov  2 23:27:49 2022 ] 	Mean training loss: 0.1546.  Mean training acc: 95.37%.
[ Wed Nov  2 23:27:49 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:27:49 2022 ] Eval epoch: 44
[ Wed Nov  2 23:28:25 2022 ] 	Mean test loss of 258 batches: 0.37105219770771586.
[ Wed Nov  2 23:28:25 2022 ] 	Top1: 89.32%
[ Wed Nov  2 23:28:25 2022 ] 	Top5: 98.23%
[ Wed Nov  2 23:28:25 2022 ] Training epoch: 45
[ Wed Nov  2 23:34:38 2022 ] 	Mean training loss: 0.1488.  Mean training acc: 95.68%.
[ Wed Nov  2 23:34:38 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:34:38 2022 ] Eval epoch: 45
[ Wed Nov  2 23:35:14 2022 ] 	Mean test loss of 258 batches: 0.3847194527557423.
[ Wed Nov  2 23:35:14 2022 ] 	Top1: 88.90%
[ Wed Nov  2 23:35:14 2022 ] 	Top5: 98.12%
[ Wed Nov  2 23:35:14 2022 ] Training epoch: 46
[ Wed Nov  2 23:41:26 2022 ] 	Mean training loss: 0.1470.  Mean training acc: 95.67%.
[ Wed Nov  2 23:41:26 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:41:27 2022 ] Eval epoch: 46
[ Wed Nov  2 23:42:02 2022 ] 	Mean test loss of 258 batches: 0.3798714245330225.
[ Wed Nov  2 23:42:02 2022 ] 	Top1: 88.79%
[ Wed Nov  2 23:42:03 2022 ] 	Top5: 98.15%
[ Wed Nov  2 23:42:03 2022 ] Training epoch: 47
[ Wed Nov  2 23:48:15 2022 ] 	Mean training loss: 0.1448.  Mean training acc: 95.66%.
[ Wed Nov  2 23:48:15 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:48:15 2022 ] Eval epoch: 47
[ Wed Nov  2 23:48:51 2022 ] 	Mean test loss of 258 batches: 0.38688584785302016.
[ Wed Nov  2 23:48:51 2022 ] 	Top1: 88.79%
[ Wed Nov  2 23:48:51 2022 ] 	Top5: 98.02%
[ Wed Nov  2 23:48:51 2022 ] Training epoch: 48
[ Wed Nov  2 23:55:04 2022 ] 	Mean training loss: 0.1394.  Mean training acc: 95.99%.
[ Wed Nov  2 23:55:04 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Nov  2 23:55:04 2022 ] Eval epoch: 48
[ Wed Nov  2 23:55:40 2022 ] 	Mean test loss of 258 batches: 0.4067335783742195.
[ Wed Nov  2 23:55:40 2022 ] 	Top1: 88.35%
[ Wed Nov  2 23:55:40 2022 ] 	Top5: 98.15%
[ Wed Nov  2 23:55:40 2022 ] Training epoch: 49
[ Thu Nov  3 00:01:52 2022 ] 	Mean training loss: 0.1306.  Mean training acc: 96.12%.
[ Thu Nov  3 00:01:52 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:01:52 2022 ] Eval epoch: 49
[ Thu Nov  3 00:02:28 2022 ] 	Mean test loss of 258 batches: 0.39847866724454617.
[ Thu Nov  3 00:02:28 2022 ] 	Top1: 88.62%
[ Thu Nov  3 00:02:28 2022 ] 	Top5: 98.12%
[ Thu Nov  3 00:02:28 2022 ] Training epoch: 50
[ Thu Nov  3 00:08:41 2022 ] 	Mean training loss: 0.1250.  Mean training acc: 96.36%.
[ Thu Nov  3 00:08:41 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:08:41 2022 ] Eval epoch: 50
[ Thu Nov  3 00:09:17 2022 ] 	Mean test loss of 258 batches: 0.39181959566970664.
[ Thu Nov  3 00:09:17 2022 ] 	Top1: 88.75%
[ Thu Nov  3 00:09:17 2022 ] 	Top5: 98.10%
[ Thu Nov  3 00:09:17 2022 ] Training epoch: 51
[ Thu Nov  3 00:15:29 2022 ] 	Mean training loss: 0.1251.  Mean training acc: 96.36%.
[ Thu Nov  3 00:15:29 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:15:29 2022 ] Eval epoch: 51
[ Thu Nov  3 00:16:05 2022 ] 	Mean test loss of 258 batches: 0.3913071443752725.
[ Thu Nov  3 00:16:05 2022 ] 	Top1: 88.60%
[ Thu Nov  3 00:16:05 2022 ] 	Top5: 98.07%
[ Thu Nov  3 00:16:05 2022 ] Training epoch: 52
[ Thu Nov  3 00:22:17 2022 ] 	Mean training loss: 0.1237.  Mean training acc: 96.33%.
[ Thu Nov  3 00:22:17 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:22:17 2022 ] Eval epoch: 52
[ Thu Nov  3 00:22:53 2022 ] 	Mean test loss of 258 batches: 0.4146061615888463.
[ Thu Nov  3 00:22:53 2022 ] 	Top1: 88.37%
[ Thu Nov  3 00:22:53 2022 ] 	Top5: 98.00%
[ Thu Nov  3 00:22:53 2022 ] Training epoch: 53
[ Thu Nov  3 00:29:05 2022 ] 	Mean training loss: 0.1255.  Mean training acc: 96.24%.
[ Thu Nov  3 00:29:05 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:29:05 2022 ] Eval epoch: 53
[ Thu Nov  3 00:29:41 2022 ] 	Mean test loss of 258 batches: 0.4163245754677427.
[ Thu Nov  3 00:29:41 2022 ] 	Top1: 88.23%
[ Thu Nov  3 00:29:41 2022 ] 	Top5: 98.07%
[ Thu Nov  3 00:29:41 2022 ] Training epoch: 54
[ Thu Nov  3 00:35:54 2022 ] 	Mean training loss: 0.1216.  Mean training acc: 96.47%.
[ Thu Nov  3 00:35:54 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:35:54 2022 ] Eval epoch: 54
[ Thu Nov  3 00:36:30 2022 ] 	Mean test loss of 258 batches: 0.4024698733561492.
[ Thu Nov  3 00:36:30 2022 ] 	Top1: 88.39%
[ Thu Nov  3 00:36:30 2022 ] 	Top5: 98.12%
[ Thu Nov  3 00:36:30 2022 ] Training epoch: 55
[ Thu Nov  3 00:42:42 2022 ] 	Mean training loss: 0.1232.  Mean training acc: 96.32%.
[ Thu Nov  3 00:42:42 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:42:42 2022 ] Eval epoch: 55
[ Thu Nov  3 00:43:18 2022 ] 	Mean test loss of 258 batches: 0.4388605231751305.
[ Thu Nov  3 00:43:18 2022 ] 	Top1: 87.94%
[ Thu Nov  3 00:43:18 2022 ] 	Top5: 97.83%
[ Thu Nov  3 00:43:18 2022 ] Training epoch: 56
[ Thu Nov  3 00:49:30 2022 ] 	Mean training loss: 0.0846.  Mean training acc: 97.85%.
[ Thu Nov  3 00:49:30 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:49:30 2022 ] Eval epoch: 56
[ Thu Nov  3 00:50:06 2022 ] 	Mean test loss of 258 batches: 0.37317643729002437.
[ Thu Nov  3 00:50:06 2022 ] 	Top1: 89.65%
[ Thu Nov  3 00:50:06 2022 ] 	Top5: 98.21%
[ Thu Nov  3 00:50:06 2022 ] Training epoch: 57
[ Thu Nov  3 00:56:18 2022 ] 	Mean training loss: 0.0663.  Mean training acc: 98.42%.
[ Thu Nov  3 00:56:18 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 00:56:18 2022 ] Eval epoch: 57
[ Thu Nov  3 00:56:54 2022 ] 	Mean test loss of 258 batches: 0.3659157012914156.
[ Thu Nov  3 00:56:54 2022 ] 	Top1: 89.62%
[ Thu Nov  3 00:56:54 2022 ] 	Top5: 98.28%
[ Thu Nov  3 00:56:54 2022 ] Training epoch: 58
[ Thu Nov  3 01:03:07 2022 ] 	Mean training loss: 0.0607.  Mean training acc: 98.56%.
[ Thu Nov  3 01:03:07 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:03:07 2022 ] Eval epoch: 58
[ Thu Nov  3 01:03:43 2022 ] 	Mean test loss of 258 batches: 0.3732863120705813.
[ Thu Nov  3 01:03:43 2022 ] 	Top1: 89.50%
[ Thu Nov  3 01:03:43 2022 ] 	Top5: 98.29%
[ Thu Nov  3 01:03:43 2022 ] Training epoch: 59
[ Thu Nov  3 01:09:55 2022 ] 	Mean training loss: 0.0570.  Mean training acc: 98.77%.
[ Thu Nov  3 01:09:55 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:09:55 2022 ] Eval epoch: 59
[ Thu Nov  3 01:10:31 2022 ] 	Mean test loss of 258 batches: 0.3720319210948755.
[ Thu Nov  3 01:10:31 2022 ] 	Top1: 89.59%
[ Thu Nov  3 01:10:31 2022 ] 	Top5: 98.23%
[ Thu Nov  3 01:10:31 2022 ] Training epoch: 60
[ Thu Nov  3 01:16:43 2022 ] 	Mean training loss: 0.0535.  Mean training acc: 98.82%.
[ Thu Nov  3 01:16:43 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:16:43 2022 ] Eval epoch: 60
[ Thu Nov  3 01:17:19 2022 ] 	Mean test loss of 258 batches: 0.3751420773017083.
[ Thu Nov  3 01:17:19 2022 ] 	Top1: 89.57%
[ Thu Nov  3 01:17:19 2022 ] 	Top5: 98.25%
[ Thu Nov  3 01:17:19 2022 ] Training epoch: 61
[ Thu Nov  3 01:23:31 2022 ] 	Mean training loss: 0.0510.  Mean training acc: 98.83%.
[ Thu Nov  3 01:23:31 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:23:31 2022 ] Eval epoch: 61
[ Thu Nov  3 01:24:07 2022 ] 	Mean test loss of 258 batches: 0.3767220020409702.
[ Thu Nov  3 01:24:07 2022 ] 	Top1: 89.54%
[ Thu Nov  3 01:24:07 2022 ] 	Top5: 98.30%
[ Thu Nov  3 01:24:07 2022 ] Training epoch: 62
[ Thu Nov  3 01:30:20 2022 ] 	Mean training loss: 0.0486.  Mean training acc: 98.93%.
[ Thu Nov  3 01:30:20 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:30:20 2022 ] Eval epoch: 62
[ Thu Nov  3 01:30:56 2022 ] 	Mean test loss of 258 batches: 0.37715584550110637.
[ Thu Nov  3 01:30:56 2022 ] 	Top1: 89.53%
[ Thu Nov  3 01:30:56 2022 ] 	Top5: 98.25%
[ Thu Nov  3 01:30:56 2022 ] Training epoch: 63
[ Thu Nov  3 01:37:08 2022 ] 	Mean training loss: 0.0475.  Mean training acc: 98.97%.
[ Thu Nov  3 01:37:08 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:37:08 2022 ] Eval epoch: 63
[ Thu Nov  3 01:37:44 2022 ] 	Mean test loss of 258 batches: 0.37562851432364347.
[ Thu Nov  3 01:37:44 2022 ] 	Top1: 89.68%
[ Thu Nov  3 01:37:44 2022 ] 	Top5: 98.23%
[ Thu Nov  3 01:37:44 2022 ] Training epoch: 64
[ Thu Nov  3 01:43:56 2022 ] 	Mean training loss: 0.0451.  Mean training acc: 99.00%.
[ Thu Nov  3 01:43:56 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:43:56 2022 ] Eval epoch: 64
[ Thu Nov  3 01:44:32 2022 ] 	Mean test loss of 258 batches: 0.3800898397687909.
[ Thu Nov  3 01:44:32 2022 ] 	Top1: 89.62%
[ Thu Nov  3 01:44:32 2022 ] 	Top5: 98.20%
[ Thu Nov  3 01:44:32 2022 ] Training epoch: 65
[ Thu Nov  3 01:50:44 2022 ] 	Mean training loss: 0.0453.  Mean training acc: 99.05%.
[ Thu Nov  3 01:50:44 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Thu Nov  3 01:50:44 2022 ] Eval epoch: 65
[ Thu Nov  3 01:51:20 2022 ] 	Mean test loss of 258 batches: 0.38108108620801867.
[ Thu Nov  3 01:51:20 2022 ] 	Top1: 89.55%
[ Thu Nov  3 01:51:20 2022 ] 	Top5: 98.22%
[ Thu Nov  3 01:51:57 2022 ] Best accuracy: 0.8968278037241463
[ Thu Nov  3 01:51:57 2022 ] Epoch number: 63
[ Thu Nov  3 01:51:57 2022 ] Model name: ./work_dir/sigmoidplus
[ Thu Nov  3 01:51:57 2022 ] Model total number of params: 1446672
[ Thu Nov  3 01:51:57 2022 ] Weight decay: 0.0004
[ Thu Nov  3 01:51:57 2022 ] Base LR: 0.1
[ Thu Nov  3 01:51:57 2022 ] Batch Size: 64
[ Thu Nov  3 01:51:57 2022 ] Test Batch Size: 64
[ Thu Nov  3 01:51:57 2022 ] seed: 1
[ Thu Nov  3 09:18:55 2022 ] Load weights from ./work_dir/sigmoidplus/runs-63-39438.pt.
[ Thu Nov  3 09:18:57 2022 ] using warm up, epoch: 5
[ Thu Nov  3 09:44:38 2022 ] Load weights from ./work_dir/sigmoidplus/runs-63-39438.pt.
[ Thu Nov  3 09:44:40 2022 ] using warm up, epoch: 5
